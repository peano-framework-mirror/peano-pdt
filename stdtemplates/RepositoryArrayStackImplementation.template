#include "__PROJECT_PATH__/repositories/RepositoryArrayStack.h"

#include "tarch/Assertions.h"
#include "tarch/timing/Watch.h"

#ifdef Parallel
#include "tarch/parallel/Node.h"
#include "tarch/parallel/NodePool.h"
#include "peano/parallel/SendReceiveBufferPool.h"
#include "peano/parallel/loadbalancing/Oracle.h"
#endif

#include "peano/datatraversal/autotuning/Oracle.h"


tarch::logging::Log __NAMESPACE__::repositories::RepositoryArrayStack::_log( "__NAMESPACE__::repositories::RepositoryArrayStack" );


__NAMESPACE__::repositories::RepositoryArrayStack::RepositoryArrayStack(
  peano::geometry::Geometry&                   geometry,
  const tarch::la::Vector<DIMENSIONS,double>&  domainSize,
  const tarch::la::Vector<DIMENSIONS,double>&  domainOffset,
  int                                          maximumSizeOfCellInOutStack,
  int                                          maximumSizeOfVertexInOutStack,
  int                                          maximumSizeOfVertexTemporaryStack
):
  _geometry(geometry),
  _cellStack(maximumSizeOfCellInOutStack),
  _vertexStack(maximumSizeOfVertexInOutStack, maximumSizeOfVertexTemporaryStack),
  _solverState(),
 __x__NONQUALIFIED_ADAPTER_TYPE__ _gridWith__NONQUALIFIED_ADAPTER_TYPE__(_vertexStack,_cellStack,_geometry,_solverState,domainSize,domainOffset,_regularGridContainer,_traversalOrderOnTopLevel),
  _repositoryState() {
  logTraceIn( "RepositoryArrayStack(...)" );
  
  _repositoryState.setAction( __NAMESPACE__::records::RepositoryState::Terminate );

  peano::datatraversal::autotuning::Oracle::getInstance().setNumberOfOracles(__NUMBER_OF_ADAPTERS__ +3);
  #ifdef Parallel
  peano::parallel::loadbalancing::Oracle::getInstance().setNumberOfOracles(__NUMBER_OF_ADAPTERS__ +3 );
  #endif
  
  logTraceOut( "RepositoryArrayStack(...)" );
}



__NAMESPACE__::repositories::RepositoryArrayStack::RepositoryArrayStack(
  peano::geometry::Geometry&                   geometry,
  int                                          maximumSizeOfCellInOutStack,
  int                                          maximumSizeOfVertexInOutStack,
  int                                          maximumSizeOfVertexTemporaryStack
):
  _geometry(geometry),
  _cellStack(maximumSizeOfCellInOutStack),
  _vertexStack(maximumSizeOfVertexInOutStack,maximumSizeOfVertexTemporaryStack),
  _solverState(),
 __x__NONQUALIFIED_ADAPTER_TYPE__ _gridWith__NONQUALIFIED_ADAPTER_TYPE__(_vertexStack,_cellStack,_geometry,_solverState,_regularGridContainer,_traversalOrderOnTopLevel),
  _repositoryState() {
  logTraceIn( "RepositoryArrayStack(Geometry&)" );
  
  _repositoryState.setAction( __NAMESPACE__::records::RepositoryState::Terminate );

  peano::datatraversal::autotuning::Oracle::getInstance().setNumberOfOracles(__NUMBER_OF_ADAPTERS__ +3);
  #ifdef Parallel
  peano::parallel::loadbalancing::Oracle::getInstance().setNumberOfOracles(__NUMBER_OF_ADAPTERS__ +3 );
  #endif
  
  logTraceOut( "RepositoryArrayStack(Geometry&)" );
}
    
   
__NAMESPACE__::repositories::RepositoryArrayStack::~RepositoryArrayStack() {
  assertion( _repositoryState.getAction() == __NAMESPACE__::records::RepositoryState::Terminate );
}


void __NAMESPACE__::repositories::RepositoryArrayStack::restart(
  const tarch::la::Vector<DIMENSIONS,double>&  domainSize,
  const tarch::la::Vector<DIMENSIONS,double>&  domainOffset,
  int                                          domainLevel
) {
  logTraceInWith3Arguments( "restart(...)", domainSize, domainOffset, domainLevel );
  #ifdef Parallel
  assertion( !tarch::parallel::Node::getInstance().isGlobalMaster());
  #endif
  
  assertion( _repositoryState.getAction() == __NAMESPACE__::records::RepositoryState::Terminate );

  _vertexStack.clear();
  _cellStack.clear();

 __x__NONQUALIFIED_ADAPTER_TYPE__ _gridWith__NONQUALIFIED_ADAPTER_TYPE__.restart(domainSize,domainOffset,domainLevel);
 
   _solverState.restart();
 
  logTraceOut( "restart(...)" );
}


void __NAMESPACE__::repositories::RepositoryArrayStack::terminate() {
  logTraceIn( "terminate()" );
  
  _repositoryState.setAction( __NAMESPACE__::records::RepositoryState::Terminate );
  
  #ifdef Parallel
  if (tarch::parallel::Node::getInstance().isGlobalMaster()) {
    tarch::parallel::NodePool::getInstance().broadcastToWorkingNodes(
      _repositoryState,
      peano::parallel::SendReceiveBufferPool::getInstance().getIterationManagementTag()
    );
  }
  peano::parallel::SendReceiveBufferPool::getInstance().terminate();
  #endif
  
 __x__NONQUALIFIED_ADAPTER_TYPE__ _gridWith__NONQUALIFIED_ADAPTER_TYPE__.terminate();
  logTraceOut( "terminate()" );
}


__NAMESPACE__::State& __NAMESPACE__::repositories::RepositoryArrayStack::getState() {
  return _solverState;
}

   
void __NAMESPACE__::repositories::RepositoryArrayStack::iterate(bool reduceState) {
  tarch::timing::Watch watch( "__NAMESPACE__::repositories::RepositoryArrayStack", "iterate(bool)", false);
  
  #ifdef Parallel
  if (tarch::parallel::Node::getInstance().isGlobalMaster()) {
    _repositoryState.setReduceState(reduceState);
    tarch::parallel::NodePool::getInstance().broadcastToWorkingNodes(
      _repositoryState,
      peano::parallel::SendReceiveBufferPool::getInstance().getIterationManagementTag()
    );
  }
  else {
    reduceState = _repositoryState.getReduceState();
  }
  #endif

  peano::datatraversal::autotuning::Oracle::getInstance().switchToOracle(_repositoryState.getAction());
  #ifdef Parallel
  peano::parallel::loadbalancing::Oracle::getInstance().switchToOracle(_repositoryState.getAction());
  #endif

  switch ( _repositoryState.getAction()) {
__x__NONQUALIFIED_ADAPTER_TYPE__    case __NAMESPACE__::records::RepositoryState::UseAdapter__NONQUALIFIED_ADAPTER_TYPE__: watch.startTimer(); _gridWith__NONQUALIFIED_ADAPTER_TYPE__.iterate(reduceState); watch.stopTimer(); _measure__NONQUALIFIED_ADAPTER_TYPE__CPUTime.setValue( watch.getCPUTime() ); _measure__NONQUALIFIED_ADAPTER_TYPE__CalendarTime.setValue( watch.getCalendarTime() ); break;
    case __NAMESPACE__::records::RepositoryState::Terminate:
      assertionMsg( false, "this branch/state should never be reached" ); 
      break;
    case __NAMESPACE__::records::RepositoryState::ReadCheckpoint:
      assertionMsg( false, "not implemented yet" );
      break;
    case __NAMESPACE__::records::RepositoryState::WriteCheckpoint:
      assertionMsg( false, "not implemented yet" );
      break;
  }
  
  #ifdef Parallel
  if (_solverState.isJoiningWithMaster()) {
    _repositoryState.setAction( __NAMESPACE__::records::RepositoryState::Terminate );
  }
  #endif
}

__x__NONQUALIFIED_ADAPTER_TYPE__ void __NAMESPACE__::repositories::RepositoryArrayStack::switchTo__NONQUALIFIED_ADAPTER_TYPE__() { _repositoryState.setAction(__NAMESPACE__::records::RepositoryState::UseAdapter__NONQUALIFIED_ADAPTER_TYPE__); }


__x__NONQUALIFIED_ADAPTER_TYPE__ bool __NAMESPACE__::repositories::RepositoryArrayStack::isActiveAdapter__NONQUALIFIED_ADAPTER_TYPE__() const { return _repositoryState.getAction() == __NAMESPACE__::records::RepositoryState::UseAdapter__NONQUALIFIED_ADAPTER_TYPE__; }


peano::grid::Checkpoint<__NAMESPACE__::Vertex, __NAMESPACE__::Cell>* __NAMESPACE__::repositories::RepositoryArrayStack::createEmptyCheckpoint() {
  return new peano::grid::Checkpoint<__NAMESPACE__::Vertex, __NAMESPACE__::Cell>();
} 


void __NAMESPACE__::repositories::RepositoryArrayStack::writeCheckpoint(peano::grid::Checkpoint<__NAMESPACE__::Vertex, __NAMESPACE__::Cell> * const checkpoint) {
  _solverState.writeToCheckpoint( *checkpoint );
  _vertexStack.writeToCheckpoint( *checkpoint );
  _cellStack.writeToCheckpoint( *checkpoint );
} 


void __NAMESPACE__::repositories::RepositoryArrayStack::setMaximumMemoryFootprintForTemporaryRegularGrids(double value) {
  _regularGridContainer.setMaximumMemoryFootprintForTemporaryRegularGrids(value);
}


void __NAMESPACE__::repositories::RepositoryArrayStack::readCheckpoint( peano::grid::Checkpoint<__NAMESPACE__::Vertex, __NAMESPACE__::Cell> const * const checkpoint ) {
  assertionMsg( checkpoint->isValid(), "checkpoint has to be valid if you call this operation" );

  _solverState.readFromCheckpoint( *checkpoint );
  _vertexStack.readFromCheckpoint( *checkpoint );
  _cellStack.readFromCheckpoint( *checkpoint );
}


#ifdef Parallel
bool __NAMESPACE__::repositories::RepositoryArrayStack::continueToIterate() {
  logTraceIn( "continueToIterate()" );

  assertion( !tarch::parallel::Node::getInstance().isGlobalMaster());

  bool result;
  if ( _solverState.hasJoinedWithMaster() ) {
    result = false;
  }
  else {
    int masterNode = tarch::parallel::Node::getInstance().getGlobalMasterRank();
    assertion( masterNode != -1 );

    _repositoryState.receive( masterNode, peano::parallel::SendReceiveBufferPool::getInstance().getIterationManagementTag(), true );

    result = _repositoryState.getAction()!=__NAMESPACE__::records::RepositoryState::Terminate;
  }
   
  logTraceOutWith1Argument( "continueToIterate()", result );
  return result;
}
#endif


void __NAMESPACE__::repositories::RepositoryArrayStack::logIterationStatistics() const {
  logInfo( "logIterationStatistics()", "|| adapter name \t || iterations \t || total CPU time [t]=s \t || average CPU time [t]=s \t || total user time [t]=s \t || average user time [t]=s  || CPU time properties  || user time properties " );  
 __x__NONQUALIFIED_ADAPTER_TYPE__  logInfo( "logIterationStatistics()", "| __NONQUALIFIED_ADAPTER_TYPE__ \t |  " << _measure__NONQUALIFIED_ADAPTER_TYPE__CPUTime.getNumberOfMeasurements() << " \t |  " << _measure__NONQUALIFIED_ADAPTER_TYPE__CPUTime.getAccumulatedValue() << " \t |  " << _measure__NONQUALIFIED_ADAPTER_TYPE__CPUTime.getValue()  << " \t |  " << _measure__NONQUALIFIED_ADAPTER_TYPE__CalendarTime.getAccumulatedValue() << " \t |  " << _measure__NONQUALIFIED_ADAPTER_TYPE__CalendarTime.getValue() << " \t |  " << _measure__NONQUALIFIED_ADAPTER_TYPE__CPUTime.toString() << " \t |  " << _measure__NONQUALIFIED_ADAPTER_TYPE__CalendarTime.toString() );
}
